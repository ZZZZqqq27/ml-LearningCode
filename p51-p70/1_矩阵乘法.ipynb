{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 矩阵乘法的原理和实现\n",
    "\n",
    "本笔记本介绍了矩阵乘法的原理、代码实现以及在TensorFlow中的实现方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 矩阵乘法的基本原理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"矩阵乘法的基本原理:\")\n",
    "print(\"- 矩阵A (m×k) 与矩阵B (k×n) 相乘，结果为矩阵C (m×n)\")\n",
    "print(\"- 矩阵C的元素C[i][j] = A的第i行与B的第j列的点积\")\n",
    "print(\"- 矩阵乘法满足结合律，但不满足交换律\")\n",
    "\n",
    "print(\"\\n矩阵乘法的数学表示:\")\n",
    "print(\"C = A × B\")\n",
    "print(\"其中 C[i][j] = Σ(A[i][k] * B[k][j]) ，k从1到矩阵A的列数\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 手动实现矩阵乘法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_multiply(A, B):\n",
    "    \"\"\"\n",
    "    手动实现矩阵乘法\n",
    "    \n",
    "    参数:\n",
    "    A: 第一个矩阵 (m×k)\n",
    "    B: 第二个矩阵 (k×n)\n",
    "    \n",
    "    返回:\n",
    "    C: 矩阵乘积 (m×n)\n",
    "    \"\"\"\n",
    "    # 检查矩阵维度是否匹配\n",
    "    if A.shape[1] != B.shape[0]:\n",
    "        raise ValueError(\"矩阵维度不匹配: A的列数必须等于B的行数\")\n",
    "    \n",
    "    # 获取矩阵维度\n",
    "    m, k = A.shape\n",
    "    _, n = B.shape\n",
    "    \n",
    "    # 初始化结果矩阵\n",
    "    C = np.zeros((m, n))\n",
    "    \n",
    "    # 计算矩阵乘积\n",
    "    for i in range(m):\n",
    "        for j in range(n):\n",
    "            for p in range(k):\n",
    "                C[i, j] += A[i, p] * B[p, j]\n",
    "    \n",
    "    return C\n",
    "\n",
    "# 测试手动实现的矩阵乘法\n",
    "A = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "B = np.array([[7, 8], [9, 10], [11, 12]])\n",
    "\n",
    "print(\"矩阵A:\")\n",
    "print(A)\n",
    "\n",
    "print(\"\\n矩阵B:\")\n",
    "print(B)\n",
    "\n",
    "C_manual = matrix_multiply(A, B)\n",
    "print(\"\\n手动实现的矩阵乘积C:\")\n",
    "print(C_manual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 使用NumPy实现矩阵乘法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用NumPy的dot函数实现矩阵乘法\n",
    "C_numpy = np.dot(A, B)\n",
    "print(\"NumPy实现的矩阵乘积C:\")\n",
    "print(C_numpy)\n",
    "\n",
    "# 验证两种方法的结果是否一致\n",
    "print(\"\\n结果是否一致:\", np.allclose(C_manual, C_numpy))\n",
    "\n",
    "# 也可以使用@运算符 (Python 3.5+)\n",
    "C_at = A @ B\n",
    "print(\"\\n使用@运算符的矩阵乘积C:\")\n",
    "print(C_at)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 矩阵乘法的性能对比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# 生成较大的随机矩阵\n",
    "size = 100\n",
    "A_large = np.random.rand(size, size)\n",
    "B_large = np.random.rand(size, size)\n",
    "\n",
    "# 测试手动实现的性能\n",
    "start_time = time.time()\n",
    "C_manual_large = matrix_multiply(A_large, B_large)\n",
    "manual_time = time.time() - start_time\n",
    "print(f\"手动实现的运行时间: {manual_time:.6f} 秒\")\n",
    "\n",
    "# 测试NumPy实现的性能\n",
    "start_time = time.time()\n",
    "C_numpy_large = np.dot(A_large, B_large)\n",
    "numpy_time = time.time() - start_time\n",
    "print(f\"NumPy实现的运行时间: {numpy_time:.6f} 秒\")\n",
    "\n",
    "# 计算性能提升\n",
    "speed_up = manual_time / numpy_time\n",
    "print(f\"NumPy比手动实现快 {speed_up:.2f} 倍\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. TensorFlow中的矩阵乘法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import tensorflow as tf\n",
    "    print(f\"TensorFlow版本: {tf.__version__}\")\n",
    "    \n",
    "    # 创建TensorFlow张量\n",
    "    tf_A = tf.constant(A)\n",
    "    tf_B = tf.constant(B)\n",
    "    \n",
    "    # 使用tf.matmul实现矩阵乘法\n",
    "    tf_C = tf.matmul(tf_A, tf_B)\n",
    "    print(\"\\nTensorFlow实现的矩阵乘积C:\")\n",
    "    print(tf_C.numpy())\n",
    "    \n",
    "    # 也可以使用@运算符\n",
    "    tf_C_at = tf_A @ tf_B\n",
    "    print(\"\\n使用@运算符的TensorFlow矩阵乘积C:\")\n",
    "    print(tf_C_at.numpy())\n",
    "    \n",
    "    # 验证结果是否一致\n",
    "    print(\"\\n与NumPy结果是否一致:\", np.allclose(tf_C.numpy(), C_numpy))\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"TensorFlow未安装，跳过TensorFlow示例\")\n",
    "    print(\"请使用 'pip install tensorflow' 安装TensorFlow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 矩阵乘法在神经网络中的应用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"矩阵乘法在神经网络中的应用:\")\n",
    "print(\"1. 线性变换层: Z = W × X + b\")\n",
    "print(\"   - W: 权重矩阵\")\n",
    "print(\"   - X: 输入特征矩阵\")\n",
    "print(\"   - b: 偏置向量\")\n",
    "print(\"   - Z: 线性变换结果\")\n",
    "\n",
    "print(\"\\n2. 批量处理:\")\n",
    "print(\"   - 输入形状: (batch_size, input_features)\")\n",
    "print(\"   - 权重形状: (input_features, output_features)\")\n",
    "print(\"   - 输出形状: (batch_size, output_features)\")\n",
    "\n",
    "print(\"\\n3. 前向传播:\")\n",
    "print(\"   - 每一层的计算都涉及矩阵乘法\")\n",
    "print(\"   - 向量化实现大大提高了计算效率\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 矩阵乘法的实际应用示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 神经网络中的线性变换示例\n",
    "def neural_network_linear_layer(X, W, b):\n",
    "    \"\"\"\n",
    "    神经网络中的线性变换层\n",
    "    \n",
    "    参数:\n",
    "    X: 输入特征 (batch_size, input_features)\n",
    "    W: 权重矩阵 (input_features, output_features)\n",
    "    b: 偏置向量 (output_features,)\n",
    "    \n",
    "    返回:\n",
    "    Z: 线性变换结果 (batch_size, output_features)\n",
    "    \"\"\"\n",
    "    return np.dot(X, W) + b\n",
    "\n",
    "# 示例参数\n",
    "batch_size = 32\n",
    "input_features = 64\n",
    "output_features = 32\n",
    "\n",
    "# 生成随机数据\n",
    "X = np.random.rand(batch_size, input_features)\n",
    "W = np.random.randn(input_features, output_features) * np.sqrt(2 / input_features)\n",
    "b = np.zeros(output_features)\n",
    "\n",
    "# 执行线性变换\n",
    "Z = neural_network_linear_layer(X, W, b)\n",
    "print(f\"输入形状: {X.shape}\")\n",
    "print(f\"权重形状: {W.shape}\")\n",
    "print(f\"偏置形状: {b.shape}\")\n",
    "print(f\"输出形状: {Z.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 矩阵乘法总结"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"矩阵乘法总结:\")\n",
    "print(\"1. 基本原理: 矩阵A (m×k) 与矩阵B (k×n) 相乘得到矩阵C (m×n)\")\n",
    "print(\"2. 实现方法:\")\n",
    "   \"- 手动实现: 三层嵌套循环，效率低\")\n",
    "   \"- NumPy实现: 使用np.dot()或@运算符，效率高\")\n",
    "   \"- TensorFlow实现: 使用tf.matmul()或@运算符，支持GPU加速\")\n",
    "print(\"3. 在神经网络中的应用:\")\n",
    "   \"- 线性变换层的计算\")\n",
    "   \"- 批量数据的并行处理\")\n",
    "   \"- 前向传播和反向传播\")\n",
    "print(\"4. 性能考虑:\")\n",
    "   \"- 向量化实现比标量实现快得多\")\n",
    "   \"- NumPy和TensorFlow利用了底层优化\")\n",
    "   \"- 对于大规模计算，考虑使用GPU加速\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}