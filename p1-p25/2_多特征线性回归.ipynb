{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 多特征线性回归\n",
    "\n",
    "本笔记本实现了多特征（多重）线性回归模型，包括数据生成、模型训练和评估。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 生成多特征模拟数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_multivariate_data(n_samples=100, n_features=3, noise=10):\n",
    "    \"\"\"\n",
    "    生成多特征线性回归的模拟数据\n",
    "    \n",
    "    参数:\n",
    "    n_samples: 样本数量\n",
    "    n_features: 特征数量\n",
    "    noise: 噪声水平\n",
    "    \n",
    "    返回:\n",
    "    X: 特征数据 (n_samples, n_features)\n",
    "    y: 目标值 (n_samples, 1)\n",
    "    true_theta: 真实参数值 (n_features, 1)\n",
    "    \"\"\"\n",
    "    # 生成0-2之间的随机特征值\n",
    "    X = 2 * np.random.rand(n_samples, n_features)\n",
    "    # 定义真实参数\n",
    "    true_theta = np.array([[10], [20], [30]])\n",
    "    # 生成线性关系的目标值，添加高斯噪声\n",
    "    y = X.dot(true_theta) + np.random.randn(n_samples, 1) * noise\n",
    "    return X, y, true_theta\n",
    "\n",
    "# 生成数据\n",
    "n_features = 3\n",
    "X, y, true_theta = generate_multivariate_data(n_features=n_features)\n",
    "print(f\"数据形状: X={X.shape}, y={y.shape}\")\n",
    "print(f\"真实参数: {true_theta.ravel()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 实现代价函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(X, y, theta):\n",
    "    \"\"\"\n",
    "    计算线性回归的代价函数\n",
    "    \n",
    "    参数:\n",
    "    X: 特征矩阵 (m, n+1)，包含偏置项\n",
    "    y: 目标值向量 (m, 1)\n",
    "    theta: 参数向量 (n+1, 1)\n",
    "    \n",
    "    返回:\n",
    "    cost: 代价函数值\n",
    "    \"\"\"\n",
    "    m = len(y)  # 样本数量\n",
    "    predictions = X.dot(theta)  # 预测值\n",
    "    errors = predictions - y  # 预测误差\n",
    "    cost = (1/(2*m)) * np.sum(np.square(errors))  # 均方误差的平均值\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 实现梯度下降算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, theta, learning_rate, n_iterations):\n",
    "    \"\"\"\n",
    "    使用梯度下降算法训练线性回归模型\n",
    "    \n",
    "    参数:\n",
    "    X: 特征矩阵 (m, n+1)，包含偏置项\n",
    "    y: 目标值向量 (m, 1)\n",
    "    theta: 初始参数向量 (n+1, 1)\n",
    "    learning_rate: 学习率\n",
    "    n_iterations: 迭代次数\n",
    "    \n",
    "    返回:\n",
    "    theta: 学习后的参数向量\n",
    "    cost_history: 每次迭代的代价函数值\n",
    "    \"\"\"\n",
    "    m = len(y)  # 样本数量\n",
    "    cost_history = np.zeros(n_iterations)  # 记录代价函数历史\n",
    "    \n",
    "    for i in range(n_iterations):\n",
    "        # 计算预测值\n",
    "        predictions = X.dot(theta)\n",
    "        # 计算误差\n",
    "        errors = predictions - y\n",
    "        # 计算梯度\n",
    "        gradients = (1/m) * X.T.dot(errors)\n",
    "        # 更新参数\n",
    "        theta = theta - learning_rate * gradients\n",
    "        # 记录当前代价函数值\n",
    "        cost_history[i] = compute_cost(X, y, theta)\n",
    "    \n",
    "    return theta, cost_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 添加偏置项 (x0=1)\n",
    "X_b = np.c_[np.ones((len(X), 1)), X]\n",
    "\n",
    "# 初始化参数\n",
    "theta_initial = np.random.randn(n_features + 1, 1)\n",
    "\n",
    "# 设置超参数\n",
    "learning_rate = 0.01\n",
    "n_iterations = 1000\n",
    "\n",
    "# 训练模型\n",
    "theta, cost_history = gradient_descent(X_b, y, theta_initial, learning_rate, n_iterations)\n",
    "\n",
    "# 打印学习结果\n",
    "print(\"真实参数:\")\n",
    "print(f\"theta1 = {true_theta[0][0]:.4f}, theta2 = {true_theta[1][0]:.4f}, theta3 = {true_theta[2][0]:.4f}\")\n",
    "\n",
    "print(\"\\n学习到的参数:\")\n",
    "print(f\"theta0 = {theta[0][0]:.4f}, theta1 = {theta[1][0]:.4f}, theta2 = {theta[2][0]:.4f}, theta3 = {theta[3][0]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 可视化训练过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(n_iterations), cost_history)\n",
    "plt.xlabel('迭代次数')\n",
    "plt.ylabel('代价函数值')\n",
    "plt.title('多特征线性回归的梯度下降训练过程')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 模型评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算训练集上的均方误差\n",
    "y_train_pred = X_b.dot(theta)\n",
    "mse = np.mean(np.square(y_train_pred - y))\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f\"训练集均方误差 (MSE): {mse:.4f}\")\n",
    "print(f\"训练集均方根误差 (RMSE): {rmse:.4f}\")\n",
    "\n",
    "# 计算R²分数\n",
    "y_mean = np.mean(y)\n",
    "ss_res = np.sum(np.square(y - y_train_pred))\n",
    "ss_tot = np.sum(np.square(y - y_mean))\n",
    "r2 = 1 - (ss_res / ss_tot)\n",
    "\n",
    "print(f\"训练集R²分数: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 特征重要性分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算特征重要性（基于参数绝对值）\n",
    "feature_importance = np.abs(theta[1:]).ravel()\n",
    "feature_importance = feature_importance / np.sum(feature_importance)  # 归一化\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(n_features), feature_importance)\n",
    "plt.xlabel('特征索引')\n",
    "plt.ylabel('相对重要性')\n",
    "plt.title('多特征线性回归的特征重要性')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}